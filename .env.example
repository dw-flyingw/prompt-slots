# LLM endpoint settings for generate-prompts
# Copy to .env and edit as needed.

# Base URL of an OpenAI-compatible API (without /chat/completions)
PROMPT_LLM_BASE_URL=http://gpt-oss-120b.models.mlds-kserve.hst.rdlabs.hpecorp.net/v1

# Model identifier
PROMPT_LLM_MODEL=openai/gpt-oss-120b

# API key (leave empty for unauthenticated endpoints)
PROMPT_LLM_API_KEY=

# Request timeout in seconds
PROMPT_LLM_TIMEOUT=45

# Temperature for generating example prompts (higher = more creative)
PROMPT_LLM_GENERATE_TEMPERATURE=0.9

# Temperature for extending/enhancing prompts (lower = more faithful)
PROMPT_LLM_EXTEND_TEMPERATURE=0.7
